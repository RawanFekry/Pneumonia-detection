{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport os\nimport PIL\nimport pathlib\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.preprocessing import image_dataset_from_directory\nimport glob\nfrom tensorflow.keras.layers.experimental.preprocessing import RandomFlip, RandomRotation\nimport matplotlib.pyplot as plt\n\nfor chest_xray, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(chest_xray, filename))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-03-31T19:48:04.395494Z","iopub.execute_input":"2022-03-31T19:48:04.395712Z","iopub.status.idle":"2022-03-31T19:48:26.505321Z","shell.execute_reply.started":"2022-03-31T19:48:04.395689Z","shell.execute_reply":"2022-03-31T19:48:26.501545Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"class_names = ['NORMAL', 'PNEUMONIA']\nTrain_data_dir = pathlib.Path('/kaggle/input/chest-xray-pneumonia/chest_xray/chest_xray/train')\nVal_data_dir = pathlib.Path('/kaggle/input/chest-xray-pneumonia/chest_xray/chest_xray/val')\nTest_data_dir = pathlib.Path('/kaggle/input/chest-xray-pneumonia/chest_xray/chest_xray/test')\nimage_count = len(list(Train_data_dir.glob('*/*.jpeg')))\nprint('num of images :',image_count)\n\nxrays = list(Train_data_dir.glob('*/*.jpeg'))\nPIL.Image.open(str(xrays[1]))","metadata":{"execution":{"iopub.status.busy":"2022-03-31T19:49:46.344246Z","iopub.execute_input":"2022-03-31T19:49:46.344487Z","iopub.status.idle":"2022-03-31T19:49:46.719323Z","shell.execute_reply.started":"2022-03-31T19:49:46.344463Z","shell.execute_reply":"2022-03-31T19:49:46.718381Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"batch_size = 16\nimg_height = 127\nimg_width = 127\nchannel = 3 \ntrain_dataset = image_dataset_from_directory(Train_data_dir,\n                                             shuffle=True,\n                                             batch_size=batch_size,\n                                             image_size=(img_height, img_width),\n                                             class_names = class_names)\n\nprint(train_dataset)\n\ntest_dataset = image_dataset_from_directory(Test_data_dir,\n                                             shuffle=True,\n                                             batch_size=batch_size,\n                                             image_size=(img_height, img_width),\n                                             class_names = class_names)\nprint(test_dataset)\n\nval_ds = tf.keras.preprocessing.image_dataset_from_directory(Val_data_dir,\n                                                             shuffle=True,\n                                                             batch_size=batch_size,\n                                                             image_size=(img_height, img_width),\n                                                             class_names = class_names)\nprint(val_ds)","metadata":{"execution":{"iopub.status.busy":"2022-03-31T19:55:40.749166Z","iopub.execute_input":"2022-03-31T19:55:40.749446Z","iopub.status.idle":"2022-03-31T19:55:42.410064Z","shell.execute_reply.started":"2022-03-31T19:55:40.749420Z","shell.execute_reply":"2022-03-31T19:55:42.408645Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"AUTOTUNE = tf.data.experimental.AUTOTUNE\ntrain_dataset = train_dataset.prefetch(buffer_size=AUTOTUNE)\ntest_dataset = test_dataset.prefetch(buffer_size=AUTOTUNE)\nval_ds = val_ds.prefetch(buffer_size=AUTOTUNE)","metadata":{"execution":{"iopub.status.busy":"2022-03-31T20:22:50.169140Z","iopub.execute_input":"2022-03-31T20:22:50.169365Z","iopub.status.idle":"2022-03-31T20:22:50.176311Z","shell.execute_reply.started":"2022-03-31T20:22:50.169342Z","shell.execute_reply":"2022-03-31T20:22:50.175150Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"def data_augmenter():\n\n    data_augmentation = tf.keras.Sequential()\n    data_augmentation.add(RandomFlip('horizontal'))\n    data_augmentation.add(RandomRotation(0.2))\n\n    \n    return data_augmentation","metadata":{"execution":{"iopub.status.busy":"2022-03-31T20:23:04.454421Z","iopub.execute_input":"2022-03-31T20:23:04.454991Z","iopub.status.idle":"2022-03-31T20:23:04.459121Z","shell.execute_reply.started":"2022-03-31T20:23:04.454963Z","shell.execute_reply":"2022-03-31T20:23:04.458328Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"preprocess_input = tf.keras.applications.mobilenet_v2.preprocess_input\nIMG_SIZE = (img_height, img_width)\nIMG_SHAPE = IMG_SIZE + (3,)\nbase_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE,\n                                               include_top=False,\n                                               weights='imagenet')","metadata":{"execution":{"iopub.status.busy":"2022-03-31T20:24:28.203206Z","iopub.execute_input":"2022-03-31T20:24:28.203468Z","iopub.status.idle":"2022-03-31T20:24:29.460238Z","shell.execute_reply.started":"2022-03-31T20:24:28.203442Z","shell.execute_reply":"2022-03-31T20:24:29.459368Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"image_batch, label_batch = next(iter(train_dataset))\nfeature_batch = base_model(image_batch)\nprint(feature_batch.shape)","metadata":{"execution":{"iopub.status.busy":"2022-03-31T20:29:11.123051Z","iopub.execute_input":"2022-03-31T20:29:11.123320Z","iopub.status.idle":"2022-03-31T20:29:12.638014Z","shell.execute_reply.started":"2022-03-31T20:29:11.123297Z","shell.execute_reply":"2022-03-31T20:29:12.637587Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"def xray_model(image_shape=IMG_SIZE, data_augmentation=data_augmenter()):\n   \n    \n    input_shape = image_shape + (3,)\n  \n    base_model = tf.keras.applications.MobileNetV2(input_shape=input_shape,\n                                                   include_top=False, \n                                                   weights='imagenet') # From imageNet\n    \n    base_model.trainable = False \n\n    inputs = tf.keras.Input(shape=input_shape) \n    \n   \n    x = data_augmentation(inputs)\n    \n    x =  preprocess_input(x)\n    \n  \n    x = base_model(x, training=False) \n    \n    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n    \n    x = tf.keras.layers.Dropout(.2)(x)\n        \n   \n    outputs = tf.keras.layers.Dense(1)(x)\n    \n    model = tf.keras.Model(inputs, outputs)\n    \n    return model","metadata":{"execution":{"iopub.status.busy":"2022-03-31T20:42:34.032658Z","iopub.execute_input":"2022-03-31T20:42:34.032893Z","iopub.status.idle":"2022-03-31T20:42:34.049409Z","shell.execute_reply.started":"2022-03-31T20:42:34.032869Z","shell.execute_reply":"2022-03-31T20:42:34.047687Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"data_augmentation = data_augmenter()\n\nfor image, _ in train_dataset.take(1):\n    plt.figure(figsize=(10, 10))\n    first_image = image[0]\n    for i in range(9):\n        ax = plt.subplot(3, 3, i + 1)\n        augmented_image = data_augmentation(tf.expand_dims(first_image, 0))\n        plt.imshow(augmented_image[0] / 255)\n        plt.axis('off')","metadata":{"execution":{"iopub.status.busy":"2022-03-31T20:42:56.226615Z","iopub.execute_input":"2022-03-31T20:42:56.226846Z","iopub.status.idle":"2022-03-31T20:42:59.307725Z","shell.execute_reply.started":"2022-03-31T20:42:56.226822Z","shell.execute_reply":"2022-03-31T20:42:59.306951Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"model2 = xray_model(IMG_SIZE, data_augmentation)\nbase_learning_rate = 0.0001\nmodel2.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=base_learning_rate),\n              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n              metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2022-03-31T20:46:45.440883Z","iopub.execute_input":"2022-03-31T20:46:45.441137Z","iopub.status.idle":"2022-03-31T20:46:46.699218Z","shell.execute_reply.started":"2022-03-31T20:46:45.441112Z","shell.execute_reply":"2022-03-31T20:46:46.698745Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"initial_epochs = 10\nhistory = model2.fit(train_dataset, validation_data=test_dataset, epochs=initial_epochs)","metadata":{"execution":{"iopub.status.busy":"2022-03-31T20:47:51.059747Z","iopub.execute_input":"2022-03-31T20:47:51.060309Z","iopub.status.idle":"2022-03-31T20:58:04.004166Z","shell.execute_reply.started":"2022-03-31T20:47:51.060282Z","shell.execute_reply":"2022-03-31T20:58:04.003560Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"acc = [0.] + history.history['accuracy']\nval_acc = [0.] + history.history['val_accuracy']\n\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nplt.figure(figsize=(8, 8))\nplt.subplot(2, 1, 1)\nplt.plot(acc, label='Training Accuracy')\nplt.plot(val_acc, label='Validation Accuracy')\nplt.legend(loc='lower right')\nplt.ylabel('Accuracy')\nplt.ylim([min(plt.ylim()),1])\nplt.title('Training and Validation Accuracy')\n\nplt.subplot(2, 1, 2)\nplt.plot(loss, label='Training Loss')\nplt.plot(val_loss, label='Validation Loss')\nplt.legend(loc='upper right')\nplt.ylabel('Cross Entropy')\nplt.ylim([0,1.0])\nplt.title('Training and Validation Loss')\nplt.xlabel('epoch')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-31T20:59:37.425554Z","iopub.execute_input":"2022-03-31T20:59:37.425790Z","iopub.status.idle":"2022-03-31T20:59:37.712092Z","shell.execute_reply.started":"2022-03-31T20:59:37.425767Z","shell.execute_reply":"2022-03-31T20:59:37.711109Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"base_model = model2.layers[4]\nbase_model.trainable = True\n\nprint(\"Number of layers in the base model: \", len(base_model.layers))\n\nfine_tune_at = 100\n\nfor layer in base_model.layers[:fine_tune_at]:\n    layer.trainable = False\n    \nloss_function=tf.keras.losses.BinaryCrossentropy(from_logits=True)\n\noptimizer = tf.keras.optimizers.Adam(lr=(0.001 * base_learning_rate))\n\nmetrics=['accuracy']\n\nmodel2.compile(optimizer=optimizer,\n              loss=loss_function,\n              metrics=['accuracy'])\n","metadata":{"execution":{"iopub.status.busy":"2022-03-31T21:02:13.157466Z","iopub.execute_input":"2022-03-31T21:02:13.158980Z","iopub.status.idle":"2022-03-31T21:02:13.187498Z","shell.execute_reply.started":"2022-03-31T21:02:13.158912Z","shell.execute_reply":"2022-03-31T21:02:13.186345Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"fine_tune_epochs = 30\ntotal_epochs =  initial_epochs + fine_tune_epochs\n\nhistory_fine = model2.fit(train_dataset,\n                         epochs=total_epochs,\n                         initial_epoch=history.epoch[-1],\n                         validation_data=test_dataset)","metadata":{"execution":{"iopub.status.busy":"2022-03-31T21:02:49.344566Z","iopub.execute_input":"2022-03-31T21:02:49.344834Z","iopub.status.idle":"2022-03-31T21:36:51.376975Z","shell.execute_reply.started":"2022-03-31T21:02:49.344800Z","shell.execute_reply":"2022-03-31T21:36:51.375987Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"acc += history_fine.history['accuracy']\nval_acc += history_fine.history['val_accuracy']\n\nloss += history_fine.history['loss']\nval_loss += history_fine.history['val_loss']\n\nmodel_json = model2.to_json()\nwith open(\"model.json\", \"w\") as json_file:\n    json_file.write(model_json)\n\nmodel2.save_weights(\"model.h5\")\nprint(\"Saved model to disk\")","metadata":{"execution":{"iopub.status.busy":"2022-03-31T21:37:12.258971Z","iopub.execute_input":"2022-03-31T21:37:12.259532Z","iopub.status.idle":"2022-03-31T21:37:12.452765Z","shell.execute_reply.started":"2022-03-31T21:37:12.259496Z","shell.execute_reply":"2022-03-31T21:37:12.451642Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(8, 8))\nplt.subplot(2, 1, 1)\nplt.plot(acc, label='Training Accuracy')\nplt.plot(val_acc, label='Validation Accuracy')\nplt.ylim([0, 1])\nplt.plot([initial_epochs-1,initial_epochs-1],\n          plt.ylim(), label='Start Fine Tuning')\nplt.legend(loc='lower right')\nplt.title('Training and Validation Accuracy')\n\nplt.subplot(2, 1, 2)\nplt.plot(loss, label='Training Loss')\nplt.plot(val_loss, label='Validation Loss')\nplt.ylim([0, 1.0])\nplt.plot([initial_epochs-1,initial_epochs-1],\n         plt.ylim(), label='Start Fine Tuning')\nplt.legend(loc='upper right')\nplt.title('Training and Validation Loss')\nplt.xlabel('epoch')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-31T21:38:02.903101Z","iopub.execute_input":"2022-03-31T21:38:02.903347Z","iopub.status.idle":"2022-03-31T21:38:03.170775Z","shell.execute_reply.started":"2022-03-31T21:38:02.903323Z","shell.execute_reply":"2022-03-31T21:38:03.170172Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"image_batch, label_batch = val_ds.as_numpy_iterator().next()\npredictions = model2.predict_on_batch(image_batch).flatten()\n\npredictions = tf.nn.sigmoid(predictions)\npredictions = tf.where(predictions < 0.5, 0, 1)\n\nprint('Predictions:\\n', predictions.numpy())\nprint('Labels:\\n', label_batch)\n\nplt.figure(figsize=(10, 10))\nfor i in range(9):\n  ax = plt.subplot(3, 3, i + 1)\n  plt.imshow(image_batch[i].astype(\"uint8\"))\n  plt.title(class_names[predictions[i]])\n  plt.axis(\"off\")","metadata":{"execution":{"iopub.status.busy":"2022-03-31T21:38:43.697610Z","iopub.execute_input":"2022-03-31T21:38:43.697852Z","iopub.status.idle":"2022-03-31T21:38:45.412227Z","shell.execute_reply.started":"2022-03-31T21:38:43.697829Z","shell.execute_reply":"2022-03-31T21:38:45.410971Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"def preprocess(images, labels):\n  return tf.keras.applications.mobilenet_v2.preprocess_input(images), labels\nval_ds = val_ds.map(preprocess)\nprint(val_ds)\nscore = model2.evaluate(val_ds, verbose=0)\n\nprint(score)\nprint(f'Test loss: {score[0]} / Test accuracy: {score[1]}')","metadata":{"execution":{"iopub.status.busy":"2022-03-31T21:39:15.006319Z","iopub.execute_input":"2022-03-31T21:39:15.006597Z","iopub.status.idle":"2022-03-31T21:39:15.274981Z","shell.execute_reply.started":"2022-03-31T21:39:15.006573Z","shell.execute_reply":"2022-03-31T21:39:15.274555Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"def prepare_image(file):\n    img = keras.preprocessing.image.load_img(file, target_size=(img_height, img_width))\n    img_array = keras.preprocessing.image.img_to_array(img)\n    img_array_expanded_dims = np.expand_dims(img_array, axis=0)\n    return img_array_expanded_dims\n","metadata":{"execution":{"iopub.status.busy":"2022-03-31T21:39:56.045925Z","iopub.execute_input":"2022-03-31T21:39:56.046169Z","iopub.status.idle":"2022-03-31T21:39:56.052176Z","shell.execute_reply.started":"2022-03-31T21:39:56.046144Z","shell.execute_reply":"2022-03-31T21:39:56.051243Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"pneumonia_file = '../input/chest-xray-pneumonia/chest_xray/val/PNEUMONIA/person1946_bacteria_4874.jpeg'\nprint(pneumonia_file)\n\nimg_pred = prepare_image(pneumonia_file)\npredictions = model2.predict(img_pred).flatten()\n\npredictions = tf.nn.sigmoid(predictions)\npredictions = tf.where(predictions < 0.5, 0, 1)\n\nprint('Predictions:\\n', predictions.numpy())\nprint('Labels:\\n', 1)","metadata":{"execution":{"iopub.status.busy":"2022-03-31T21:40:04.703814Z","iopub.execute_input":"2022-03-31T21:40:04.704090Z","iopub.status.idle":"2022-03-31T21:40:05.634168Z","shell.execute_reply.started":"2022-03-31T21:40:04.704065Z","shell.execute_reply":"2022-03-31T21:40:05.633217Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"normal_file = '../input/chest-xray-pneumonia/chest_xray/val/NORMAL/NORMAL2-IM-1427-0001.jpeg'\nprint(normal_file)\n\nimg_pred = prepare_image(normal_file)\npredictions = model2.predict(img_pred).flatten()\npredictions = tf.nn.sigmoid(predictions)\npredictions = tf.where(predictions < 0.5, 0, 1)\n\nprint('Predictions:\\n', predictions.numpy())\nprint('Labels:\\n', 0)","metadata":{"execution":{"iopub.status.busy":"2022-03-31T21:41:45.185585Z","iopub.execute_input":"2022-03-31T21:41:45.185822Z","iopub.status.idle":"2022-03-31T21:41:45.315250Z","shell.execute_reply.started":"2022-03-31T21:41:45.185799Z","shell.execute_reply":"2022-03-31T21:41:45.314511Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"normal_file = '../input/chest-xray-pneumonia/chest_xray/val/NORMAL/NORMAL2-IM-1431-0001.jpeg'\nprint(normal_file)\n\nimg_pred = prepare_image(normal_file)\npredictions = model2.predict(img_pred).flatten()\n\n\npredictions = tf.nn.sigmoid(predictions)\npredictions = tf.where(predictions < 0.5, 0, 1)\n\nprint('Predictions:\\n', predictions.numpy())\nprint('Labels:\\n', 0)","metadata":{"execution":{"iopub.status.busy":"2022-03-31T21:42:28.281432Z","iopub.execute_input":"2022-03-31T21:42:28.281696Z","iopub.status.idle":"2022-03-31T21:42:28.388879Z","shell.execute_reply.started":"2022-03-31T21:42:28.281669Z","shell.execute_reply":"2022-03-31T21:42:28.387532Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"pneumonia_file = '../input/chest-xray-pneumonia/chest_xray/val/PNEUMONIA/person1946_bacteria_4874.jpeg'\nprint(pneumonia_file)\n\nimg_pred = prepare_image(normal_file)\npredictions = model2.predict(img_pred).flatten()\n\npredictions = tf.nn.sigmoid(predictions)\npredictions = tf.where(predictions < 0.5, 0, 1)\n\nprint('Predictions:\\n', predictions.numpy())\nprint('Labels:\\n', 1)","metadata":{"execution":{"iopub.status.busy":"2022-03-31T21:42:56.409677Z","iopub.execute_input":"2022-03-31T21:42:56.409969Z","iopub.status.idle":"2022-03-31T21:42:56.507202Z","shell.execute_reply.started":"2022-03-31T21:42:56.409942Z","shell.execute_reply":"2022-03-31T21:42:56.506732Z"},"trusted":true},"execution_count":29,"outputs":[]}]}